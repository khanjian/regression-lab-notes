---
title: "PSTAT 126"
subtitle: "Lab 4"
author: "Roupen Khanjian"
date: "Spring 2021"
output:
  pdf_document: default
  word_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
library(faraway) # Functions and Datasets for Books by Julian Faraway 
library(alr4) # Data to Accompany Applied Linear Regression 4th Edition
library(tidyverse) # Easily Install and Load the 'Tidyverse'
library(GGally) # Extension to 'ggplot2'
library(palmerpenguins) # Palmer Archipelago (Antarctica) Penguin Data
```


\tableofcontents

# Multiple Linear Regression

#### SLR in matrix form:

$$\left(\begin{array}{c}{Y_{1}} \\ {Y_{2}} \\ {\vdots} \\ {Y_{n}}\end{array}\right)=\left(\begin{array}{cc}{1} & {x_{1}} \\ {1} & {x_{2}} \\ {\vdots} & {\vdots} \\ {1} & {x_{n}}\end{array}\right)\left(\begin{array}{l}{\beta_{0}} \\ {\beta_{1}}\end{array}\right)+\left(\begin{array}{c}{\varepsilon_{1}} \\ {\varepsilon_{2}} \\ {\vdots} \\ {\varepsilon_{n}}\end{array}\right)$$

#### MLR with 2 predictor variables

$$\left(\begin{array}{c}{Y_{1}} \\ {Y_{2}} \\ {\vdots} \\ {Y_{n}}\end{array}\right)=\left(\begin{array}{ccc}{1} & {x_{11}} & {x_{12}} \\ {1} & {x_{21}} & {x_{22}} \\ {\vdots} & {\vdots} & {\vdots}\\ {1} & {x_{n1}} & {x_{n2}}\end{array}\right)\left(\begin{array}{l}{\beta_{0}} \\ {\beta_{1}} \\ {\beta_{2}}\end{array}\right)+\left(\begin{array}{c}{\varepsilon_{1}} \\ {\varepsilon_{2}} \\ {\vdots} \\ {\varepsilon_{n}}\end{array}\right)$$

#### MLR
$$\boldsymbol{Y}=\boldsymbol{X} \boldsymbol{\beta}+\varepsilon$$

* $\boldsymbol{X}$ = design matrix (n x p)
* $\beta$ = coefficient vector (p x 1)
* **Y** = (n x 1) 
* If n > p and the columns of $\boldsymbol{X}$ are linearly independent, then $\left(X^{T} X\right)^{-1}$ exists & the OLS estimator is:

$$\boldsymbol{\hat{\beta} = (X^TX)^{-1}X^T{y}}$$


## Example in R 

Data from faraway package. `gala` dataset is on species diversity on the Galapagos Islands

```{r}
data(gala)
head(gala[,-2])
glimpse(gala[,-2])

lmod <- lm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data = gala)
summary(lmod)

x <- model.matrix(~ Area + Elevation + Nearest + Scruz + Adjacent, gala)

head(x)
```

* `model.matrix`  takes all your predictor values and adds a column of 1's to it to make the **design matrix**

```{r}
n = dim(gala)[1] 
p = 5 + 1
x_same <- cbind(intercept = rep(1, n), gala[,3:7])
head(x_same)

```

* Can also make the design matrix manually

```{r}
y <- gala$Species

```

* response vector **Y** of length n

```{r}
xtxi <- solve(t(x) %*% x)
```

* Computing $(X^{T}X)^{-1}$
* `solve(A)` computes $A^{-1}$

```{r}
xtxi %*% t(x) %*% y
```

Above we obtain our $\boldsymbol{\hat{\beta} = (X^TX)^{-1}X^T{y}}$ values

```{r}
solve(crossprod(x,x)) %*% crossprod(x,y)

```

Can also use the function `crossprod(a,b)` which computes $a^Tb$

```{r}
coef(lmod)
```

Can see our coefficients from the summary output as well.   


## Dataset example 

Dataset for today is on Horror Movies. Boo!
```{r}
# Data source
horror_movies <- 
read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv")
```

\newpage
```{r}
# Subset the data (In case you want to replicate, don't need to know these functions for this course)
horror <- horror_movies %>% 
  drop_na(budget, movie_run_time, review_rating) %>% # remove missing values
  mutate(movie_run_time = 
           as.numeric( # remove the min and convert to numeric
             str_remove_all(movie_run_time, "min"))) %>%  
  filter(str_detect(budget, "(?<=\\$)\\d+")) %>% # filter for movies using $
  mutate(budget = str_remove_all(budget, ",")) %>% # remove commas
  mutate(budget = 
           as.numeric( # get rid of $ and convert to numeric
             str_replace_all(budget, "[^[:alnum:]]", ""))) %>% 
  filter(budget < 50000000 & budget > 5000000 & 
         movie_run_time < 160 & str_detect(language, "English")) %>%
  select(c(budget, review_rating, movie_run_time))

head(horror)

horror$budget <- horror$budget * 1e-06 # Changed budget to in millions of dollars
head(horror)

budget <- horror$budget 
movie_run_time <- horror$movie_run_time # Movie length in minutes
review_rating <- horror$review_rating # Number between 0 - 10
```

### MLR model wusing lm()

```{r}
model_full <- lm(movie_run_time ~ budget + 
                   review_rating) # MLR model

summary(model_full)
model_budget <- lm(movie_run_time ~
                    budget) # SLR model with budget

model_rating <- lm(movie_run_time ~
                    review_rating) # SLR model with review rating

## SLR Model with no intercept:

model_budget_no_intercept <- lm(movie_run_time ~ -1 + budget)

summary(model_budget_no_intercept)


```

\newpage
```{r}
coef(model_budget)
coef(model_rating)
coef(model_full)
```

If we are trying to predict movie run time by budget and review ratings, according to the above coefficients our model would be as follows.  

Let $x_{i1} =$ Budget and $x_{i2} =$ Review rating.   

$$\hat{Y}_i = 68.220855 + 0.374024x_{i1} + 4.461262x_{i2}$$

For example if we have a movie that has a budget of 1 million dollars and a review rating of 5, then we would expect this movie to be 
`r  68.220855 + 0.374024*1 + 4.461262*5` minutes long.

```{r}
68.220855 + 0.374024*1 + 4.461262*5
```


## Visualizing MLR

```{r}
pairs(horror, lower.panel = NULL)  

ggpairs(horror)
```

\newpage


```{r}
# from car package which is loaded when you load the package alr4
scatterplotMatrix(~ review_rating+ movie_run_time + budget, col = "red", smooth = F)

```

\newpage

## Global F-test found in summary() output

$H_0 : \beta_1 = \beta_2 = ... = \beta_p = 0$ vs $H_1 : \beta_j \ne 0$ for some $j = 1, 2, ... , p$

&nbsp;

```{r}

summary(model_full)

```


## Confidence intervals for mean response

* Here we use $x_0 = 50$ bill length (mm)

**95% Confidence interval for Mean response**
```{r}

penguins_noChinstrap <- penguins %>% 
  filter(species != "Chinstrap") %>% 
  drop_na(bill_length_mm, body_mass_g)

model <- lm(body_mass_g ~ bill_length_mm , data = penguins_noChinstrap)

n <- nrow(penguins_noChinstrap) # number of observations
x <- penguins_noChinstrap$bill_length_mm # predictor variable
y <- penguins_noChinstrap$body_mass_g # response variable
x_bar <- mean(x) # mean of bill_length_mm
y_bar <- mean(y) # mean of body_mass_g
Sxx <- sum((x - x_bar) ^ 2)
sigma_hat <- summary(model)$sigma # Residual Standard Error (RSE)
Yhat_50 <- # predicated body mass when bill length is 50 mm
  as.numeric(coef(model)[1] + coef(model)[2] * 50) 
y_hat <- fitted(model) # fitted values

se_50 <-  sigma_hat*sqrt(1/n + (50 - x_bar)^2/Sxx) # se of y_hat(x_0)
t_pct <-  qt(p = 0.975, df = n - 2) # t-statistic
CI_95 <-  c(Yhat_50 - se_50*t_pct, Yhat_50 + se_50*t_pct) 
CI_95

predict(model, newdata = data.frame(bill_length_mm = 50), 
        level = 0.95, interval = 'confidence')

# Can look at multiple values for x0. 
predict(model, newdata = data.frame(bill_length_mm = c(50, 55)), 
        level = 0.95, interval = 'confidence')
```


### Visualizing confidence interval bands

```{r}


ngrid <-  274
grid <-  seq(min(x), max(x), length = ngrid)
new <- data.frame(bill_length_mm = grid)
p1 <- predict(model, new, se.fit = TRUE, interval = "confidence", level = 0.95)

conf_pred_tib <- tibble(x,y, y_hat, new = new$bill_length_mm, 
                        UL_c = p1$fit[,3], LL_c = p1$fit[,2])
```

\newpage

```{r}
ggplot(data = conf_pred_tib) +
  geom_point(aes(x = x, y = y), color = "darkgreen", alpha = 0.8, size = 2) +
  geom_line(aes(x = x, y = y_hat), color = "blue") +
  geom_line(aes(x = new, y = UL_c), color = "purple", linetype = "twodash") +
  geom_line(aes(x = new, y = LL_c), color = "purple", linetype = "twodash") +
  scale_x_continuous(breaks = seq(30, 60, by = 10)) +
  scale_y_continuous(breaks = seq(2000, 7000, by = 1000)) +
  labs(x = "bill length (mm)",
       y = "body mass (grams)",
       title = "95% Confidence bands") +
  theme_minimal()


```


